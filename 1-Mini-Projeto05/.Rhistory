#configurando o diretorio de trabalho
getwd()
#Operadores Relacionais
7 + 7
#Soma
7 + 7
#subtração
7 - 4
#Soma
7 + 7
#subtração
7 - 4
16 %% 3
matrix (c(1,2,3,4,5,6), nr = 2)
matrix (c(1,2,3,4,5,6), nr = 3)
matrix (c(1,2,3,4,5,6), nr = 6)
matrix (c(1,2,3,4,5,6), nc = 2)
meus_dados = c(1:10)
matrix(data = meus_dados, nrow = 5, ncol = 2, byrow = T)
mat <- matrix(c(2,3,4,5), nr = 2)
mat
mat[1,2]
matriz = 1:3
diag(matriz)
matriz
vetor = diag(matriz)
diag(vetor)
vetor
w <- matrix (c(2,4,8,12), mr = 2, ncol = 2)
w <- matrix (c(2,4,8,12), nr = 2, ncol = 2)
w
t(w)
solve(W)
solve(w)
mat1 <- matrix(c(2,3,4,5),nr = 2)
mat1
mat2 <- matrix(c(6,7,8,9),nr = 2)
mat2
mat1 * mat2
mat1 + mat2
mat1 / mat2
x = c(1:4)
x
y <- matrix(c(2,3,4,5),nr = 2)
x * y
x
y
x * y
mat3 <- matrix(c('Terra', 'Marte', 'Saturno', 'Netuno'), nr =2)
mat3
dinames(mat3) = (list (c("linha1", "linha2"), c("cokuna1", "coluna2")))
dimnames(mat3) = (list (c("linha1", "linha2"), c("cokuna1", "coluna2")))
mat3
dimnames(mat3) = (list (c("linha1", "linha2"), c("coluna1", "coluna2")))
mat3
matrix (c(1,2,3,4), nr =2, nc = 2, dimnames = list(c("linha1", "linha2"), c("coluna1", "coluna2") ))
#COMBINANDO MATRIZES
mat4 <- matrix(c(2,3,4,5), nr = 2)
mat4
mat5 <- matrix(c(6,7,8,9), nr = 2)
mat5
cbindo(mat4, mat5)
rbind(mat4, mat5)
rbind(mat4, mat5) #coluna
cbindo(mat4, mat5) #linha
cbind(mat4, mat5) #linha
C(mat4)
c(mat4)
mat2 <- matrix(1:90, 10)
mat2
?sample
mat2[sample(1:50, 10)] = NA
mat2
setwd("C:/Users/conta/OneDrive/Documentos/DataScience/BIG_DATA_R_AZURE/Cap03")
lst2 <- list(2, 3, 5, 7, 11, 13)
getwd()
getwd()
setwd("C:/Users/conta/OneDrive/Documentos/DataScience/BIG_DATA_R_AZURE/5-Mini-Projeto4")
getwd()
credit.df <- read.csv("credit_dataset.csv", header = TRUE, sep = ",")
credit.df <- read.csv("credit_dataset.csv", header = TRUE, sep = ",")
head(credit.df)
to.factors <- function(df, variables){
for (variable in variables){
df[[variable]] <- as.factor(df[[variable]])
}
return(df)
}
scale.features <- function(df, variables){
for (variable in variables){
df[[variable]] <- scale(df[[variable]], center=T, scale=T)
}
return(df)
}
numeric.vars <- c("credit.duration.months", "age", "credit.amount")
credit.df <- scale.features(credit.df, numeric.vars)
categorical.vars <- c('credit.rating', 'account.balance', 'previous.credit.payment.status',
'credit.purpose', 'savings', 'employment.duration', 'installment.rate',
'marital.status', 'guarantor', 'residence.duration', 'current.assets',
'other.credits', 'apartment.type', 'bank.credits', 'occupation',
'dependents', 'telephone', 'foreign.worker')
credit.df <- to.factors(df = credit.df, variables = categorical.vars)
View(credit.df)
credit.df <- to.factors(df = credit.df, variables = categorical.vars)
credit.df <- to.factors(df = credit.df, variables = categorical.vars)
indexes <- sample(1:nrow(credit.df), size = 0.6 * nrow(credit.df))
train.data <- credit.df[indexes,]
test.data <- credit.df[-indexes,]
library(caret)
library(randomForest)
run.feature.selection <- function(num.iters=20, feature.vars, class.var){
set.seed(10)
variable.sizes <- 1:10
control <- rfeControl(functions = rfFuncs, method = "cv",
verbose = FALSE, returnResamp = "all",
number = num.iters)
results.rfe <- rfe(x = feature.vars, y = class.var,
sizes = variable.sizes,
rfeControl = control)
return(results.rfe)
}
rfe.results <- run.feature.selection(feature.vars = train.data[,-1],
class.var = train.data[,1])
rfe.results
varImp((rfe.results))
varImp((rfe.results))
rfe.results
varImp((rfe.results))
library(caret)
library(ROCR)
source("plot_utils.R")
test.feature.vars <- test.data[,-1]
test.class.var <- test.data[,1]
formula.init <- "credit.rating ~ ."
formula.init <- as.formula(formula.init)
lr.model <- glm(formula = formula.init, data = train.data, family = "binomial")
summary(lr.model)
lr.predictions <- predict(lr.model, test.data, type="response")
lr.predictions <- round(lr.predictions)
confusionMatrix(table(data = lr.predictions, reference = test.class.var), positive = '1')
formula <- "credit.rating ~ ."
formula <- as.formula(formula)
control <- trainControl(method = "repeatedcv", number = 10, repeats = 2)
model <- train(formula, data = train.data, method = "glm", trControl = control)
importance <- varImp(model, scale = FALSE)
plot(importance)
formula.new <- "credit.rating ~ account.balance + credit.purpose + previous.credit.payment.status + savings + credit.duration.months"
formula.new <- as.formula(formula.new)
lr.model.new <- glm(formula = formula.new, data = train.data, family = "binomial")
summary(lr.model.new)
lr.predictions.new <- predict(lr.model.new, test.data, type = "response")
lr.predictions.new <- round(lr.predictions.new)
confusionMatrix(table(data = lr.predictions.new, reference = test.class.var), positive = '1')
formula <- "credit.rating ~ ."
formula <- as.formula(formula)
control <- trainControl(method = "repeatedcv", number = 10, repeats = 2)
model <- train(formula, data = train.data, method = "glm", trControl = control)
importance <- varImp(model, scale = FALSE)
plot(importance)
test.feature.vars <- test.data[,-1]
test.class.var <- test.data[,1]
# Construindo um modelo de regressão logística
formula.init <- "credit.rating ~ ."
formula.init <- as.formula(formula.init)
lr.model <- glm(formula = formula.init, data = train.data, family = "binomial")
# Visualizando o modelo
summary(lr.model)
# Testando o modelo nos dados de teste
lr.predictions <- predict(lr.model, test.data, type="response")
lr.predictions <- round(lr.predictions)
formula <- "credit.rating ~ ."
formula <- as.formula(formula)
control <- trainControl(method = "repeatedcv", number = 10, repeats = 2)
model <- train(formula, data = train.data, method = "glm", trControl = control)
importance <- varImp(model, scale = FALSE)
plot(importance)
formula.new <- "credit.rating ~ account.balance + credit.purpose + previous.credit.payment.status + savings + credit.duration.months"
formula.new <- as.formula(formula.new)
lr.model.new <- glm(formula = formula.new, data = train.data, family = "binomial")
summary(lr.model.new)
lr.predictions.new <- predict(lr.model.new, test.data, type = "response")
lr.predictions.new <- round(lr.predictions.new)
confusionMatrix(table(data = lr.predictions.new, reference = test.class.var), positive = '1')
lr.model.best <- lr.model
lr.prediction.values <- predict(lr.model.best, test.feature.vars, type = "response")
predictions <- prediction(lr.prediction.values, test.class.var)
par(mfrow = c(1,2))
plot.roc.curve(predictions, title.text = "Curva ROC")
plot.pr.curve(predictions, title.text = "Curva Precision/Recall")
confusionMatrix(table(data = lr.predictions.new, reference = test.class.var), positive = '1')
temp_files <- list.files(pattern = ".csv")
getwd()
# Obtendo localidades únicas
region %>%
slice(1:length(unique(region$location)))
# Mapeando a ocorrência do vírus Zika
# Obs: Caso tenha problemas com a acentuação, consulte este link:
# https://support.rstudio.com/hc/en-us/articles/200532197-Character-Encoding
# Configurando o diretório de trabalho
# Coloque entre aspas o diretório de trabalho que você está usando no seu computador
setwd("~/Dropbox/DSA/BigDataAnalytics-R-Azure/Projetos/Mini-Projeto05")
getwd()
# http://combateaedes.saude.gov.br/pt/situacao-epidemiologica
# Carregando os pacotes
# devtools::install_github("wch/webshot")
library(dplyr)
library(ggplot2)
# Listando os arquivos e gerando uma lista com os respctivos nomes
temp_files <- list.files(pattern = ".csv")
temp_files
# Carregando todos os arquivos em um único objeto
myfiles <- lapply(temp_files, read.csv, stringsAsFactors = FALSE)
# Resumo dos arquivos
str(myfiles, 1)
lapply(myfiles, names)[1]
lapply(myfiles, head,2)[1:2]
# Organizando o shape dos dados
brazil <- do.call(rbind, myfiles)
View(brazil)
brazil <- brazil %>%
mutate(report_date = as.Date(report_date))
# Visualizando o dataset
glimpse(brazil)
# Transformando o dataframe um uma tabela dplyr e removendo as colunas 5 a 7
brazil <- brazil %>% select(-(6:7))
# Visualizando as primeiras 20 linhas
brazil %>% slice (1:20)
# Para cada reporting_date nós temos 5 regiões
brazil %>% filter(location_type == "region")
brazil %>% filter(location_type == "region") %>%
ggplot(aes(x = report_date, y = value, group = location, color = location)) +
geom_line() +
geom_point() +
ggtitle("Casos de Zika por Região do Brasil")
# Separando as regiões e Visualizando os Dados
region <- brazil %>%
filter(location_type == "region")
region %>%
ggplot(aes(x =location, y = value)) + geom_bar(stat = "identity") +
ylab("Número de Casos Reportados") + xlab("Region") +
ggtitle("Casos de Zika Reportados no Brasil")
region %>%
slice(1:length(unique(region$location))) %>%
arrange(desc(value)) %>%
mutate(location = factor(location, levels = location,ordered = TRUE)) %>%
ggplot(aes(x = location, y = value)) + geom_bar(stat = "identity") +
ylab("Número de Casos Reportados") + xlab("Region") +
ggtitle("Casos de Zika Reportados no Brasil")
# Obtendo localidades únicas
region %>%
slice(1:length(unique(region$location)))
# Organziando as localidades únicas por número de casos reportados
region %>%
slice(1:length(unique(region$location))) %>%
arrange(desc(value))
# Criando variáveis do tipo fator
region %>%
slice(1:length(unique(region$location))) %>%
arrange(desc(value)) %>%
mutate(location = factor(location,levels=location,ordered=TRUE)) %>%
glimpse()
# Agrupando o Sumarizando
brazil_totals <- brazil %>% filter(location=="Brazil")
region_totals <- brazil %>% filter(location_type=="region") %>%
group_by(report_date,location) %>%
summarize(tot = sum(value))
# Padronizar os dados e remover as sumarizações
regvec <- vector()
length(regvec) <- nrow(brazil)
for (ii in 1:nrow(brazil)) {
if (brazil[ii,]$location_type != "region")  {
regvec[ii] <- newlab
} else {
newlab <- brazil[ii,]$location
regvec[ii] <- newlab
}
}
# Agregando o vetor de regiões ao dataframe brasil
statedf <- cbind(brazil,regvec)
# Eliminar o sumário de linhas por região e país
statedf <- statedf %>% filter(location != "Brazil")
statedf <- statedf %>% filter(location_type != "region")
# Gerar o total por regiões a partir dos dados transformados
statedf %>% group_by(report_date,regvec) %>%
summarize(tot=sum(value)) -> totals
# Gerando os mapas de cada estado do Brasil
library(ggmap)
longlat <- geocode(unique(statedf$location)) %>%
mutate(loc = unique(statedf$location))
# Salvando os geocodes do dataframe statedf e salvando em um novo dataframe chamado formapping
statedf %>% filter(as.character(report_date) == "2016-06-11") %>%
group_by(location) %>% summarize(cases = sum(value)) %>%
inner_join(longlat, by = c("location" = "loc")) %>%
mutate(LatLon = paste(lat, lon, sep = ":")) -> formapping
# Visualizando os dados
head(formapping)
# Formatando a saída e gerando um movo dataframe chamado long_formapping
num_of_times_to_repeat <- formapping$cases
long_formapping <- formapping[rep(seq_len(nrow(formapping)),
num_of_times_to_repeat),]
# Visualizando os dados
head(long_formapping)
# Instalando o pacote leaflet
install.packages("leaflet")
library(leaflet)
# Gerando o mapa com o dataframe
# Aplique o zoom
leaflet(long_formapping) %>%
addTiles() %>%
addMarkers(clusterOptions = markerClusterOptions())
getwd()
setwd("C:/Users/conta/OneDrive/Documentos/DataScience/BIG_DATA_R_AZURE/1-Mini-Projeto05")
temp_files <- list.files(pattern = ".csv")
temp_files
# Mapeando a ocorrência do vírus Zika
# Obs: Caso tenha problemas com a acentuação, consulte este link:
# https://support.rstudio.com/hc/en-us/articles/200532197-Character-Encoding
# Configurando o diretório de trabalho
# Coloque entre aspas o diretório de trabalho que você está usando no seu computador
setwd("C:/Users/conta/OneDrive/Documentos/DataScience/BIG_DATA_R_AZURE/1-Mini-Projeto05")
getwd()
# http://combateaedes.saude.gov.br/pt/situacao-epidemiologica
# Carregando os pacotes
# devtools::install_github("wch/webshot")
library(dplyr)
library(ggplot2)
# Listando os arquivos e gerando uma lista com os respctivos nomes
temp_files <- list.files(pattern = ".csv")
temp_files
# Carregando todos os arquivos em um único objeto
myfiles <- lapply(temp_files, read.csv, stringsAsFactors = FALSE)
# Resumo dos arquivos
str(myfiles, 1)
lapply(myfiles, names)[1]
lapply(myfiles, head,2)[1:2]
# Organizando o shape dos dados
brazil <- do.call(rbind, myfiles)
View(brazil)
brazil <- brazil %>%
mutate(report_date = as.Date(report_date))
# Visualizando o dataset
glimpse(brazil)
# Transformando o dataframe um uma tabela dplyr e removendo as colunas 5 a 7
brazil <- brazil %>% select(-(6:7))
# Visualizando as primeiras 20 linhas
brazil %>% slice (1:20)
# Para cada reporting_date nós temos 5 regiões
brazil %>% filter(location_type == "region")
brazil %>% filter(location_type == "region") %>%
ggplot(aes(x = report_date, y = value, group = location, color = location)) +
geom_line() +
geom_point() +
ggtitle("Casos de Zika por Região do Brasil")
# Separando as regiões e Visualizando os Dados
region <- brazil %>%
filter(location_type == "region")
region %>%
ggplot(aes(x =location, y = value)) + geom_bar(stat = "identity") +
ylab("Número de Casos Reportados") + xlab("Region") +
ggtitle("Casos de Zika Reportados no Brasil")
region %>%
slice(1:length(unique(region$location))) %>%
arrange(desc(value)) %>%
mutate(location = factor(location, levels = location,ordered = TRUE)) %>%
ggplot(aes(x = location, y = value)) + geom_bar(stat = "identity") +
ylab("Número de Casos Reportados") + xlab("Region") +
ggtitle("Casos de Zika Reportados no Brasil")
# Obtendo localidades únicas
region %>%
slice(1:length(unique(region$location)))
# Organziando as localidades únicas por número de casos reportados
region %>%
slice(1:length(unique(region$location))) %>%
arrange(desc(value))
# Criando variáveis do tipo fator
region %>%
slice(1:length(unique(region$location))) %>%
arrange(desc(value)) %>%
mutate(location = factor(location,levels=location,ordered=TRUE)) %>%
glimpse()
# Agrupando o Sumarizando
brazil_totals <- brazil %>% filter(location=="Brazil")
region_totals <- brazil %>% filter(location_type=="region") %>%
group_by(report_date,location) %>%
summarize(tot = sum(value))
# Padronizar os dados e remover as sumarizações
regvec <- vector()
length(regvec) <- nrow(brazil)
for (ii in 1:nrow(brazil)) {
if (brazil[ii,]$location_type != "region")  {
regvec[ii] <- newlab
} else {
newlab <- brazil[ii,]$location
regvec[ii] <- newlab
}
}
# Agregando o vetor de regiões ao dataframe brasil
statedf <- cbind(brazil,regvec)
# Eliminar o sumário de linhas por região e país
statedf <- statedf %>% filter(location != "Brazil")
statedf <- statedf %>% filter(location_type != "region")
# Gerar o total por regiões a partir dos dados transformados
statedf %>% group_by(report_date,regvec) %>%
summarize(tot=sum(value)) -> totals
# Gerando os mapas de cada estado do Brasil
library(ggmap)
longlat <- geocode(unique(statedf$location)) %>%
mutate(loc = unique(statedf$location))
# Salvando os geocodes do dataframe statedf e salvando em um novo dataframe chamado formapping
statedf %>% filter(as.character(report_date) == "2016-06-11") %>%
group_by(location) %>% summarize(cases = sum(value)) %>%
inner_join(longlat, by = c("location" = "loc")) %>%
mutate(LatLon = paste(lat, lon, sep = ":")) -> formapping
# Visualizando os dados
head(formapping)
# Formatando a saída e gerando um movo dataframe chamado long_formapping
num_of_times_to_repeat <- formapping$cases
long_formapping <- formapping[rep(seq_len(nrow(formapping)),
num_of_times_to_repeat),]
# Visualizando os dados
head(long_formapping)
# Instalando o pacote leaflet
install.packages("leaflet")
library(leaflet)
# Gerando o mapa com o dataframe
# Aplique o zoom
leaflet(long_formapping) %>%
addTiles() %>%
addMarkers(clusterOptions = markerClusterOptions())
install.packages("leaflet")
